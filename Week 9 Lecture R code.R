##################
# Gibbs Sampling #
##################
set.seed(2)

# Example: Bivariate Normal Distribution
# length of chain (number of random samples)
n <- 5000 
# burn-in length
burn <- 1000
# the chain, a bivariate sample
X <- matrix(0, n, 2)

# set up the parameter values for bivariate normal distribution
rho <- 0.75
mu1 <- 0
mu2 <- 2
sigma1 <- 1
sigma2 <- 0.5

# Gibbs Sampling algorithm
# initialize
X[1,] <- c(1, 2)

# conditional distribution follows normal distribution so we use rnorm()
for(i in 1:(n-1)){
  x2 <- X[i,2]
  X[i+1,1] <- rnorm(1, mu1 + rho*(sigma1/sigma2)*(x2-mu2), sqrt((1-rho^2)*sigma1^2))
  x1 <- X[i+1,1]
  X[i+1,2] <- rnorm(1, mu2 + rho*(sigma2/sigma1)*(x1-mu1), sqrt((1-rho^2)*sigma2^2)) 
}

b <- burn + 1
x <- X[b:n, ]

# compare sample statistics to parameters
# mu_1 = 0, mu_2 = 2
apply(x, 2, mean) 
# var_1 = 1 var_2 = 0.25
cov(x) 
# rho = 0.75
cor(x) 

# plot the bivariate normals samples generated by Gibbs sampling
plot(x[,1], x[,2], main = "", cex=0.5)


#####################################
# Bayesian Simple Linear Regression #
#####################################

# observed data
advertise <- read.csv("Advertising.csv", header = T)
head(advertise)

# Simple Linear Regression (OLS estimator)
ols <- lm(sales ~ TV, data = advertise)
summary(ols)

plot(advertise$TV, advertise$sales)
abline(ols, col = "red")

# Bayesian Linear Regression
# Priors
mu <- 0
tau <- 1000
a <- 0.01
b <- 0.01

# length of chain (number of random samples)
n <- 30000 
# the chain, a multivariate
beta0_beta1_sigma2 <- matrix(0, n, 3)

# Gibbs Sampling algorithm
# initialize
beta0 <- 0
beta1 <- 0
sigma2 <- 1
beta0_beta1_sigma2[1,] <- c(beta0, beta1, sigma2)

Y <- advertise$sales
X <- advertise$TV
N <- length(Y)

for(i in 1:(n-1)){
	# sample beta0
	V <- N/sigma2 + 1/tau   
	M <- sum(Y - beta1*X)/sigma2 +  mu/tau
	beta0 <- rnorm(1, M/V, 1/sqrt(V))
	# sample beta1
	V <- sum(X^2)/sigma2 + 1/tau   
	M <- sum((Y - beta0)*X)/sigma2 +  mu/tau 
	beta1 <- rnorm(1, M/V, 1/sqrt(V))
	# sample sigma2
	A <- N/2 + a
	B <- sum((Y - beta0 - beta1*X)^2)/2 + b
	sigma2 <- 1/rgamma(1, shape = A, rate = B) 
	
	# update the target sample
	beta0_beta1_sigma2[i+1,] <- c(beta0, beta1, sigma2)
}

# the bayes estimtor of beta0, beta1, and sigma2
# posterior mean
apply(beta0_beta1_sigma2, 2, mean)

# posterior standard deviation
apply(beta0_beta1_sigma2, 2, sd)
